{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청 함수\n",
    "def getSource(site) :\n",
    "    # 헤더 정보\n",
    "    header_info = {\n",
    "        'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.146 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # 요청한다.\n",
    "    response = requests.get(site, headers = header_info)\n",
    "    # print(response.text)\n",
    "    \n",
    "    # bs4 객체 생성\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 페이지의 데이터를 수집해 저장하는 함수\n",
    "def getData(soup) :\n",
    "    # 전체를 가지고 있는 태그를 가져온다.\n",
    "    a1 = soup.select_one('#mArticle > ul.list_movie')\n",
    "#     print(a1)\n",
    "\n",
    "    # 영화들을 가져온다.\n",
    "    a2 = a1.select('li')\n",
    "#     print(a2)\n",
    "\n",
    "    # 데이터를 담을 딕셔너리\n",
    "    data_dict = {\n",
    "        '제목':[],\n",
    "        '평점':[],\n",
    "        '개봉날짜':[],\n",
    "        '예매율':[]\n",
    "    }\n",
    "    \n",
    "    # 영화 수 만큼 반복한다.\n",
    "    for a3 in a2 :\n",
    "        # 영화 제목을 가져온다.\n",
    "        a4 = a3.select_one('div.wrap_movie > div > a')\n",
    "        data1 = a4.text.strip()\n",
    "#         print(data1)\n",
    "\n",
    "        # 평점을 가져온다.\n",
    "        a5 = a3.select('div.wrap_movie > span.info_grade > a > span.wrap_grade.grade_netizen > span.num_grade')\n",
    "        b1 = int(a5[0].text)\n",
    "        b2 = int(a5[2].text)\n",
    "        data2 = f'{b1}.{b2}'\n",
    "#         print(data2)\n",
    "        \n",
    "        # 개봉 날짜와 예매율\n",
    "        a6 = a3.select_one(' div.wrap_movie > span.info_state')\n",
    "        b3 = a6.text.split('・')\n",
    "        \n",
    "        data3 = b3[0].strip()\n",
    "        \n",
    "        if len(b3) == 2 :\n",
    "            data4 = b3[1].strip()\n",
    "        else :\n",
    "            data4 = np.nan\n",
    "\n",
    "        \n",
    "        # 개봉 날짜에서 '개봉일' 문자열 제거\n",
    "        data3 = data3.replace('개봉','').strip()\n",
    "        data3 = data3.replace('재','').strip()\n",
    "        \n",
    "        # 예매율\n",
    "        if len(b3) == 2 :\n",
    "            data4 = data4.replace('예매율','').strip()\n",
    "            data4 = data4.replace('%','').strip()\n",
    "\n",
    "        \n",
    "#         print(data1)\n",
    "#         print(data2)\n",
    "#         print(data3)\n",
    "#         print(data4)\n",
    "        # 영화 포스터\n",
    "        a7 = a3.select_one('div.info_movie > span > img')\n",
    "\n",
    "        src_attr = a7.attrs['src']\n",
    "#         print(src_attr)\n",
    "        if len(src_attr) > 0 :\n",
    "            # 포스터 이미지가 존재할 경우\n",
    "            # 이미지 데이터를 읽어온다.\n",
    "            with urlopen('https:'+ src_attr) as f1 :\n",
    "                img_data = f1.read()\n",
    "                \n",
    "            # 영화 제목의 특수문자를 제거한다.\n",
    "            filename = data1.replace(':', '-')\n",
    "            filename = filename.replace('/', ' ')\n",
    "            filename = filename.replace(';', '')\n",
    "\n",
    "            \n",
    "            \n",
    "            # 저장\n",
    "            with open(f'poster/{filename}.jpg','wb') as f2 :\n",
    "                f2.write(img_data)\n",
    "\n",
    "            \n",
    "        \n",
    "        data_dict['제목'].append(data1)\n",
    "        data_dict['평점'].append(data2)\n",
    "        data_dict['개봉날짜'].append(data3)\n",
    "        data_dict['예매율'].append(data4)\n",
    "        \n",
    "    df1= pd.DataFrame(data_dict)\n",
    "    if os.path.exists('data2.csv') == False :\n",
    "        # 파일이 없을 경우\n",
    "        df1.to_csv('data2.csv', encoding='utf-8-sig', index=False)\n",
    "    else :\n",
    "        df1.to_csv('data2.csv',encoding='utf-8-sig' , index=False, header = False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음페이지 존재 여부 확인하는 함수\n",
    "def getNext(soup):\n",
    "\n",
    "    # 페이지 번호 중 a 태그를 가져온다.\n",
    "    a_tag = soup.select('#mArticle > div.paging_movie > span > a')\n",
    "#     print(a_tag)\n",
    "\n",
    "    # 페이지 번호 중 em 태그를 가져온다.\n",
    "    em_tag =soup.select_one('#mArticle > div.paging_movie > span > em')\n",
    "#     print(em_tag)\n",
    "    \n",
    "    #  a 태그 중 제일 마지막 태그의 숫자 값을 가져온다.\n",
    "    a1 = a_tag[-1].text.strip()\n",
    "    # em 태그의 숫자값을 가져온다.\n",
    "    a2 = em_tag.text.strip()\n",
    "    a2 = a2.replace('현재페이지','')\n",
    "    \n",
    "    \n",
    "#     print(a1)\n",
    "#     print(a2)\n",
    "\n",
    "    if int(a1) > int(a2) :\n",
    "        # 마지막 a 태그의 숫자가 em태그의 숫자보다 더 큰 경우\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduled : 6 수집중\n",
      "수집 완료\n"
     ]
    }
   ],
   "source": [
    "page_name = 'released'\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    \n",
    "    clear_output()\n",
    "    \n",
    "    site = f'https://movie.daum.net/premovie/{page_name}?reservationOnly=N&sort=reservation&page={page}'\n",
    "    \n",
    "    print(f'{page_name} : {page} 수집중')\n",
    "    \n",
    "    soup= getSource(site)\n",
    "    getData(soup)\n",
    "    chk = getNext(soup)\n",
    "    \n",
    "    if chk == False :\n",
    "        if page_name == 'released' :\n",
    "            page_name = 'scheduled'\n",
    "            page = 1\n",
    "        else :\n",
    "            print('수집 완료')\n",
    "            break\n",
    "    else :\n",
    "        page = page + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('data2.csv')\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
